version: '3.8'

services:
  frontend:
    build:
      context: . 
    container_name: frontend
    ports:
      - "8080:8080" 
    networks:
      - place-tale
    depends_on:
      - backend

  backend:
    build: 
      context: ./backend
    container_name: backend
    ports:
      - "3030:3030"
    networks:
      - place-tale
    environment:
      CONTENT_GENERATION_MODEL: "@cf/meta/llama-3.1-70b-instruct"
      CLOUDFLARE_API_TOKEN: "58MJLczvrvYf9ttZi2EZzJux-HFdQmaZjrfYgFN1"

  nginx:
    image: nginx:latest
    container_name: nginx
    volumes:
      - ./nginx/default.conf:/etc/nginx/conf.d/default.conf
    ports:
      - "80:80"
    depends_on:
      - backend
      - frontend
    networks:
      - place-tale
networks:
  place-tale:
